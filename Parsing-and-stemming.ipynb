{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anush/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/anush/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import xml.sax\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from collections import defaultdict as ddic\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Stemmer import Stemmer\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleID = {}\n",
    "fileNo = 0\n",
    "pageNo = 0\n",
    "iMap = ddic(list)\n",
    "offset = 0\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = Stemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../enwiki-20200801-pages-articles-multistream1.xml-p1p30303'\n",
    "sergey = '../Sergey_brin.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeFile(pageno, imap,fileno,titleoffset):\n",
    "    \n",
    "    global titleID\n",
    "    prevoff = titleoffset\n",
    "    stats = []\n",
    "    for k in sorted(imap):\n",
    "        initial = k + ' '\n",
    "        fi =  imap[k]\n",
    "        initial += ' '.join(fi)\n",
    "        stats.append(initial)\n",
    "    fname = '../index' + str(fileno) + '.txt'\n",
    "    with open(fname,'w') as f:\n",
    "        f.write('\\n'.join(stats))\n",
    "    stats = []\n",
    "    statOffset = []\n",
    "    \n",
    "    for k in tqdm(sorted(titleID)):\n",
    "        initial = str(k) + ' ' + titleID[k].strip()\n",
    "        stats.append(initial)\n",
    "        statOffset.append(str(prevoff))\n",
    "        prevoff += len(initial) + 1\n",
    "    \n",
    "    with open('../title.txt','a') as f:\n",
    "        f.write('\\n'.join(stats))\n",
    "        f.write('\\n')\n",
    "    \n",
    "    with open('../titleOffset','a') as f:\n",
    "        f.write('\\n'.join(statOffset))\n",
    "        f.write('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanupText(stats):\n",
    "    global stop_words\n",
    "    global stemmer\n",
    "    \n",
    "    stats = stats.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    stats = re.sub(r'http[^\\ ]*\\ ',r' ',stats)\n",
    "    stats = re.sub(r'&nbsp;|&lt;|&gt;|&amp;|&quot;|&apos;', r' ',stats)\n",
    "    stats = re.sub(r'[^A-Za-z0-9]+',r' ',stats)\n",
    "    stats = stats.split()\n",
    "    stats = [i for i in stats if not i in stop_words]\n",
    "    stats = stemmer.stemWords(stats)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index():\n",
    "    def __init__(self,refs,extlink,cat,body,info,title):\n",
    "        self.title = title\n",
    "        self.refs = refs\n",
    "        self.extlink = extlink\n",
    "        self.cat = cat\n",
    "        self.body = body\n",
    "        self.info = info\n",
    "    def MakingDicts(self):\n",
    "        total = ddic(int)\n",
    "        \n",
    "        title = ddic(int)\n",
    "        for i in self.title:\n",
    "            title[i] += 1\n",
    "            total[i] += 1\n",
    "        \n",
    "        refs = ddic(int)\n",
    "        for i in self.refs:\n",
    "            refs[i] += 1\n",
    "            total[i] += 1\n",
    "            \n",
    "        \n",
    "        extlink = ddic(int)\n",
    "        for i in self.extlink:\n",
    "            extlink[i] += 1\n",
    "            total[i] += 1\n",
    "            \n",
    "        cat = ddic(int) \n",
    "        for i in self.cat:\n",
    "            cat[i] += 1\n",
    "            total[i] += 1\n",
    "            \n",
    "        \n",
    "        body = ddic(int)\n",
    "        for i in self.body:\n",
    "            body[i] += 1\n",
    "            total[i] += 1\n",
    "            \n",
    "        info = ddic(int)\n",
    "        for i in self.info:\n",
    "            info[i] += 1\n",
    "            total[i] += 1\n",
    "        return (total,refs,extlink,cat,body,info,title)\n",
    "    \n",
    "    def IndexMapping(self,total,refs,extlink,cat,body,info,title,pageno,iMap):\n",
    "        \n",
    "        \n",
    "        for word in total.keys():\n",
    "            initial = 'D' + str(pageno)\n",
    "            if refs[word] > 0:\n",
    "                initial += 'r' + str(refs[word])\n",
    "            if extlink[word] > 0:\n",
    "                initial += 'e' + str(extlink[word])\n",
    "            if cat[word] > 0:\n",
    "                initial += 'c' + str(cat[word])\n",
    "            if body[word] > 0:\n",
    "                initial += 'b' + str(body[word])\n",
    "            if info[word] > 0:\n",
    "                initial += 'i' + str(info[word])\n",
    "            if title[word] > 0:\n",
    "                initial += 't' + str(title[word])\n",
    "            \n",
    "            iMap[word].append(initial)\n",
    "        return iMap\n",
    "    \n",
    "    def InitIndex(self,pageno,iMap):\n",
    "            \n",
    "        (total,refs,extlink,cat,body,info,title) = self.MakingDicts()\n",
    "        iMap = self.IndexMapping(total,refs,extlink,cat,body,info,title,pageno,iMap)\n",
    "        \n",
    "        return iMap, pageno\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegexExp():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def findUsefulText(self, info):\n",
    "        stats = info.split('\\n')\n",
    "        refs = []\n",
    "        extlinks = []\n",
    "        cat = []\n",
    "        for l in stats:\n",
    "            if re.search(r'ref',l):\n",
    "                x = re.sub(r'.*title[\\ ]*=[\\ ]*([^\\|]*).*',r'\\1',l)\n",
    "                refs.append(x)\n",
    "            if re.search(r'\\[\\[category',l):\n",
    "                x = re.sub(r'\\[\\[category:(.*)\\]\\]',r'\\1',l)\n",
    "                cat.append(x)\n",
    "            if re.match(r'\\*[\\ ]*\\[',l):\n",
    "                extlinks.append(l)\n",
    "        \n",
    "        return (refs,extlinks,cat)\n",
    "    \n",
    "    def findUsefulInfo(self,info):\n",
    "        stats = info.split('\\n')\n",
    "        i = []\n",
    "        flag = 0\n",
    "        \n",
    "        for l in stats:\n",
    "            if re.match(r'\\{\\{infobox', l):\n",
    "                flag = 1\n",
    "                x = re.sub('\\{\\{infobox(.*)',r'\\1',l)\n",
    "                i.append(x)\n",
    "            elif flag == 1:\n",
    "                if l == '}}':\n",
    "                    flag = 0\n",
    "                    continue\n",
    "                i.append(l)\n",
    "        empty = []\n",
    "        stats = cleanupText(' '.join(i))\n",
    "        return stats\n",
    "                \n",
    "        \n",
    "    \n",
    "    def textHandling(self,ID,text,title):\n",
    "        text = text.lower()\n",
    "        cleaned_text = text.split('==references==')\n",
    "#         print(data)\n",
    "        if len(cleaned_text) == 1:\n",
    "            cleaned_text = text.split('== references== ')\n",
    "        if len(cleaned_text) == 1:\n",
    "            refs = []\n",
    "            extlink = []\n",
    "            cat = []\n",
    "        else:\n",
    "            useful = cleaned_text[1]\n",
    "            (refs,extlink,cat) = self.findUsefulText(useful)\n",
    "            refs = cleanupText(' '.join(refs))\n",
    "            extlink = cleanupText(' '.join(extlink))\n",
    "            cat = cleanupText(' '.join(cat))\n",
    "        title = title.lower()\n",
    "        useful = cleaned_text[0]\n",
    "        info = self.findUsefulInfo(useful)\n",
    "        stats = re.sub(r'\\{\\{.*\\}\\}',r' ',useful)\n",
    "        body = cleanupText(stats)\n",
    "        \n",
    "        return (refs,extlink,cat,body,info,title)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XMLHandler(xml.sax.ContentHandler):\n",
    "    def __init__(self):\n",
    "        self.CurrentData = ''\n",
    "        self.title = ''\n",
    "        self.ID = ''\n",
    "        self.idFlag = 0\n",
    "        self.text = \"\"\n",
    "        self.pageNo = 0\n",
    "        self.iMap = ddic(list)\n",
    "        self.fileNo = 0\n",
    "        \n",
    "    def startElement(self,tag,attributes):\n",
    "        self.CurrentData = tag\n",
    "            \n",
    "    def endElement(self,tag):\n",
    "        if self.CurrentData == 'title':\n",
    "            pass\n",
    "#             print(self.title)\n",
    "        elif self.CurrentData == 'text':\n",
    "            pass\n",
    "#             print(self.text)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if tag == 'page':\n",
    "            self.pageNo += 1\n",
    "            clear_output(wait=True)\n",
    "            print(self.pageNo)\n",
    "            reg = RegexExp()\n",
    "            refs,extlink,cat,body,info,title = reg.textHandling(self.ID,self.text,self.title)\n",
    "            indexer = Index(refs,extlink,cat,body,info,title)\n",
    "            self.iMap,self.pageNo = indexer.InitIndex(self.pageNo,self.iMap)\n",
    "            \n",
    "            global fileNo,pageNo,iMap,offset,titleID\n",
    "            titleID[self.pageNo] = self.title.strip().encode(\"ascii\",errors=\"ignore\").decode()\n",
    "            \n",
    "            \n",
    "            if self.pageNo%25000 == 0:\n",
    "                offest = writeFile(self.pageNo, self.iMap,self.fileNo,offset)\n",
    "                self.iMap = ddic(list)\n",
    "                titleID = {}\n",
    "                self.fileNo += 1\n",
    "            \n",
    "            fileNo = self.fileNo\n",
    "            pageNo = self.pageNo\n",
    "            iMap = self.iMap\n",
    "            \n",
    "            \n",
    "            self.CurrentData = ''\n",
    "            self.title = ''\n",
    "            self.ID = ''\n",
    "            self.idFlag = 0\n",
    "            self.text = ''\n",
    "            \n",
    "        \n",
    "        \n",
    "    def characters(self,content):\n",
    "        if self.CurrentData == 'title':\n",
    "            self.title += content\n",
    "        elif self.CurrentData == 'text':\n",
    "            self.text += content\n",
    "        elif self.CurrentData == 'id' and self.idFlag == 0:\n",
    "            self.ID = content\n",
    "            self.idFlag = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser():\n",
    "    def __init__(self,filename):\n",
    "        self.parser = xml.sax.make_parser()\n",
    "        self.parser.setFeature(xml.sax.handler.feature_namespaces, 0)\n",
    "        self.handler =  XMLHandler()\n",
    "        self.parser.setContentHandler(self.handler)\n",
    "        self.parser.parse(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19797\n"
     ]
    }
   ],
   "source": [
    "parser = Parser(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19797/19797 [00:00<00:00, 573055.78it/s]\n"
     ]
    }
   ],
   "source": [
    "writeFile(pageNo, iMap,fileNo,offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
